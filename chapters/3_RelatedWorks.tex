\chapter{Related Work}
\label{chp:relatedWork}

\begin{comment}
    
\section{Fuzzing of Android native libraries and harness generation}
Fuzzing of Android native libraries poses challenges beyond conventional user-space fuzzing due to the \gls{jni} boundary, lifecycle constraints, and the need for realistic cross-language call sequences. POIROT automatically synthesises consumer-specific harnesses for closed-source Android libraries by analysing Java-side usage and supporting bidirectional \gls{jni} interactions, enabling large-scale campaigns that uncovered thousands of unique crashes \cite{poirot-usenix25}. Atlas similarly targets Android closed-source native libraries with a cross-language fuzzing framework and automatic harness generation \cite{atlas-issta24}. Beyond the Android setting, FuzzGen synthesises library-specific fuzzers by inferring API contracts and integrating with \gls{libfuzzer} to reach deep states \cite{fuzzgen-usenix20}. Prior engineering work shows that reproducing \gls{art} behaviour and \gls{jni} semantics is critical for validity and reproducibility of results \cite{polito-android-native-fuzzing}. As to fuzzing engines, \gls{aflpp} extends greybox fuzzing with a rich ecosystem of mutators and instrumentation \cite{aflpp-woot20}, while \gls{libfuzzer} offers tight integration with LLVM sanitizers for in-process fuzzing \cite{libfuzzer-llvm}. Sanitizers such as \gls{asan} and \gls{hwasan} are widely used to diagnose memory-safety defects during fuzzing on Android \cite{asan-android-aosp,hwasan-ndk}.

\section{Crash triage and LLM-based vulnerability classification}
Traditional crash triage combines bucketing, deduplication, and heuristic \emph{exploitability} estimation, but typically requires expert oversight and offers limited precision across diverse crash types \cite{scb-ase18,igor-ccs21}. Recent studies investigate \gls{llm}-assisted triage. CASEY reports non-trivial accuracy for CWE classification (68\%) and severity identification (73.6\%) on an NVD-derived corpus, indicating that \gls{llm}s can streamline parts of vulnerability triage \cite{casey-aic25}. LProtector explores \gls{llm}-driven vulnerability detection for C/C++ projects with retrieval augmentation, highlighting benefits and pitfalls of model-in-the-loop security analysis \cite{lprotector-2024}. Broader surveys benchmark \gls{llm}s and agents for practical software security, consolidating evidence that model judgements improve when provided with structured context and repository-level signals, but also documenting variability across tasks and datasets \cite{acl25-llm-benchmark-slr,slr-llm-vuln-2025}. These findings motivate tool-grounded designs for triage under Android/\gls{jni} constraints.

\section{Tool grounding with \gls{mcp} for program analysis and reverse engineering}
Tool grounding aims to reduce hallucinations and improve faithfulness by letting the \gls{llm} query authoritative artefacts. The \gls{mcp} standardises how models connect to external tools and data sources \cite{mcp-overview,anthropic-mcp}. In our setting, grounding uses Jadx to retrieve bytecode/manifest context and Ghidra for disassembly/decompilation. An emerging ecosystem of \gls{mcp} servers exposes reverse-engineering capabilities of Ghidra to \gls{llm}-based clients (e.g., symbol and function listings, decompilation), facilitating evidence-linked reasoning \cite{ghidra-mcp-laurie,ghidra-mcp-suid}. While promising, the security surface of tool integrations must be considered; recent supply-chain incidents around \gls{mcp} servers highlight the need for permission scoping and integrity checks \cite{mcp-supplychain-incident}. Our design leverages \gls{mcp} to fetch verifiable snippets (stack frames, function names, minimal decompiled code) that the triager references in its rationale.

\section{Positioning}
Compared to POIROT and Atlas, which focus on automating harness generation and fuzzing at scale \cite{poirot-usenix25,atlas-issta24}, our work targets the \emph{post-fuzzing} triage stage for Android native crashes. Relative to CASEY/LProtector and survey results on \gls{llm}-for-security \cite{casey-aic25,lprotector-2024,acl25-llm-benchmark-slr,slr-llm-vuln-2025}, our contribution is a tool-grounded pipeline that couples \gls{mcp}-mediated access to Jadx/Ghidra with crash artefacts from POIROT, aiming to improve precision, explainability, and analyst verification for \gls{jni}-mediated memory-safety issues.

\end{comment}

The proposed approach lies at the confluence of coverage-guided fuzzing and bottom-up harness generation, and recent applications of \gls{llm}s to vulnerability classification and triage. We organise prior work into four strands: (i) methodologies for automated vulnerability discovery via fuzzing; (ii) \gls{llm}-assisted harness generation and mitigation of false positives; (iii) \gls{llm}-based vulnerability triage and assessment; and (iv) reasoning and validation-feedback loops that improve reliability of automated analyses.

\section{Automated vulnerability detection and fuzzing}

Fuzz testing remains a principal technique for uncovering defects and security issues at scale. A useful distinction is between top-down fuzzing of public entry points and bottom-up fuzzing of internal functions, the latter demanding specialised drivers to translate unstructured inputs into well-formed, semantically valid API arguments \cite{jiang2024fuzzing}. Recent \gls{llm}-assisted fuzzing frameworks demonstrate that language models can increase input diversity and sustain long-horizon exploration, provided that prompting strategies adaptively distil documentation and examples into effective prompts and evolve them during the fuzzing loop \cite{10.1145/3597503.3639121}. However, bottom-up strategies are especially prone to invalid drivers and unrealistic executions, which in turn inflate the rate of spurious crashes.

\section{\gls{llm}-assisted harness generation and false-positive mitigation}

Two complementary directions address the fidelity of generated drivers and the veracity of reported crashes. First, \emph{knowledge-driven} harness generation uses code metadata, API documentation and usage correlations to guide \gls{llm}s; a \emph{sanitizer} module then fixes compilation/runtime issues and performs crash analysis to separate harness misuse from genuine bugs, feeding newly inferred constraints back into the knowledge base \cite{liupromefuzz}. Second, multi-agent schemes for large-scale driver generation propose (i) a Function Analyzer that extracts input/state constraints from code to proactively reduce misuse, and (ii) a Crash Validation agent that checks whether a crash is feasible from real entry points, filtering out a substantial fraction of false positives \cite{amusuo2025falsecrashreducermitigatingfalsepositive}. These works collectively indicate that constraint-aware generation and post hoc feasibility checks are both necessary to keep precision high when scaling bottom-up fuzzing.

\section{\gls{llm}-based vulnerability triage and assessment}

Beyond discovering crashes, several studies target automated triage: mapping issues to \gls{cwe} categories and estimating severity under \gls{cvss}. CASEY shows that \gls{llm}s can classify \gls{cwe} and approximate \gls{cvss} labels from structured descriptions and compact code hunks, with fine-tuning improving accuracy and stability on an NVD-derived dataset \cite{torkamani2025streamlining}. LProtector employs binary classification with Retrieval-Augmented Generation (RAG) to inject domain knowledge and reports improved F1 on Big-Vul, suggesting that retrieval helps compensate for limited in-context capacity \cite{sheng2024lprotectorllmdrivenvulnerabilitydetection}. A broader multi-task evaluation finds that while traditional transformers remain competitive for pure detection, code-centric \gls{llm}s excel at assessment/localisation when provided with key contextual artefacts (e.g., \gls{cve} descriptions, commits) \cite{10706805}. Earlier work on continuous monitoring likewise reports useful initial classification performance but highlights sensitivity to noisy descriptions and the need for stronger validation signals \cite{10456393}. Together, these results motivate a triage pipeline that privileges concise, structured context and emphasises evidence that analysts can verify.

\section{Reasoning and validation-feedback loops}

Reliability improves when \gls{llm} reasoning is coupled with external validation. A case study on automated vulnerability repair (VRpilot) demonstrates that explicit chain-of-thought prompts and iterative feedback from compiler errors, tests, and sanitizer diagnostics produce more plausible and correct patches than prompting alone \cite{10.1145/3664646.3664770}. By analogy, triage decisions can benefit from similar feedback: stack traces, minimized inputs, and runtime diagnostics can drive iterative re-analysis to confirm root causes and filter out artefacts of invalid harnesses or unreachable paths.

\section{Positioning with respect to Android native libraries}

The thesis specifically targets crashes uncovered when fuzzing C/C++ libraries integrated via the \gls{jni}. Prior work on \gls{llm}-assisted harnessing highlights the twin challenges that are particularly acute in the Android context: (i) constructing realistic call sequences across the managed–native boundary, and (ii) ensuring that reported crashes correspond to feasible executions rather than artefacts of driver misuse \cite{liupromefuzz, amusuo2025falsecrashreducermitigatingfalsepositive}. We therefore draw on constraint-aware driver generation and feasibility checks to motivate a triage stage that leverages structured artefacts (stack frames, call sequences, compact code snippets) and reports verifiable evidence alongside \gls{cwe}/\gls{cvss} judgements \cite{10706805, torkamani2025streamlining}.

\paragraph{Scope within this thesis.}
Our focus is on post-fuzzing \emph{triage} rather than on harness generation per se. Nevertheless, we incorporate the practical insights of knowledge-driven driver synthesis and agentic crash validation to (i) anticipate common false-positive modes during analysis and (ii) shape the evidence presented to the triager (e.g., concise hunks rather than full files), consistent with findings that excessive or noisy context degrades classification quality \cite{liupromefuzz, torkamani2025streamlining}.

\section*{\textcolor{red}{Note on tool-grounding and \gls{mcp} in cybersecurity}}
\textcolor{red}{While our evaluation relies solely on the cited literature above, our method employs tool-grounding to reduce hallucinations and improve verifiability. In particular, \gls{mcp}-mediated access to reverse-engineering tools (e.g., bytecode and native artefacts) can supply the compact, high-value context recommended by prior work. A systematic review of \gls{mcp} applications in cybersecurity will be included in a future revision, with explicit citations once curated.}

\begin{comment}
    \paragraph{Summary.}
Prior work shows that \gls{llm}s can help generate harnesses, reduce false positives via constraint extraction and feasibility checking, and automate \gls{cwe}/\gls{cvss} labelling when provided with focused, structured context \cite{amusuo2025falsecrashreducermitigatingfalsepositive,liupromefuzz,torkamani2025streamlining,10706805,10.1145/3597503.3639121}. Our thesis builds on these insights to design a tool-grounded triage pipeline tailored to Android’s managed–native boundary, aiming to deliver evidence-linked, analyst-verifiable decisions for crashes produced by fuzzing native libraries.
\end{comment}

\textcolor{red}{https://arxiv.org/pdf/2510.18508}