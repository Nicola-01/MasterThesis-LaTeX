\chapter{Background}
\label{chp:backgroud}

\section{Android Native}
Android itself relies extensively on native C/C++ libraries within its core architecture. Many system components and services, such as the runtime, media stack, graphics pipeline, and hardware abstraction layer (HAL), are implemented in native code for reasons of performance, portability, and direct hardware access \cite{android-platform}. The framework exposes parts of this functionality to applications through Java/Kotlin \glspl{api}, enabling managed code to invoke native system services when needed. 

At the system level, Android’s C standard library and dynamic linker are provided by \emph{Bionic}, a lightweight libc/libm/libdl implementation optimised for mobile environments \cite{bionic-maint}. This design allows the platform to combine managed execution (via the \gls{art}) with efficient, low-level components responsible for performance-critical and hardware-dependent operations. Figure~\ref{fig:androidStack} illustrates the Android platform architecture, highlighting how native libraries underpin the runtime, system services, and the HAL.

Beyond the platform itself, developers can extend Android apps with their own native code through the \gls{ndk}.

The advantages of native development stem from the ability to execute compiled machine code directly on the target CPU, allowing finer-grained optimisation and efficient memory use, important for resource-constrained mobile devices. It also enables hardware acceleration and access to specialised \glspl{api} (e.g., GPU, DSP, or sensor interfaces), making it indispensable in areas like augmented or virtual reality, game engines (e.g., Unity, Unreal), and device-specific system utilities.% \textcolor{red}{Dovrei cercare una citazione}

However, using native code extends the scope of Android applications beyond the safety of the managed runtime. Developers must explicitly handle memory allocation and deallocation, thread synchronisation, and exception propagation, as these are not automatically managed by the \gls{art}. Cross-ABI compatibility, debugging complexity, and maintenance across Android versions further increase the development load. Consequently, the \gls{ndk} is recommended only when its benefits outweigh these costs \cite{android-ndk-getting-started,android-ndk-concepts,jni-tips}.

This capability to use native code extends the reach of Android apps beyond the managed runtime but also introduces explicit responsibilities for developers. Native code must handle its own memory management, threading and exception handling. This is significantly different from pure Java/Kotlin development.

\begin{figure}
    \centering
    \input{tikzpicture/androidStack}
    \caption[Android software stack.]%
    {Android software stack \cite{android-platform}}
    \label{fig:androidStack}
\end{figure}

\subsection{\glsxtrlong{ndk}}
The \gls{ndk} is a collection of tools, headers, and libraries that enable developers to embed C and C++ code within Android applications and interact natively with hardware, sensors, and system \glspl{api} \cite{android-ndk-getting-started}. The \gls{ndk} supports compilation into shared (and static) libraries that can be packaged inside the \gls{apk}, and offers native interfaces for tasks such as sensor input, asset loading, and more \cite{android-ndk-concepts}.

Developers typically adopt native code for three main reasons:
\begin{itemize}
  \item \textbf{Performance optimization:} achieving low-latency processing in compute-intensive domains such as graphics, signal processing, physics, or cryptography.
  \item \textbf{Library reuse:} integrating existing C/C++ libraries (e.g.\ cryptography, compression, codecs) to avoid rewriting functionality in Java/Kotlin.
  \item \textbf{Hardware or vendor-specific access:} interacting directly with low-level or proprietary \glspl{api} (e.g.\ custom sensors, specialized accelerators) not exposed in the Java framework.
\end{itemize}

However, using the \gls{ndk} comes with tradeoffs. Native development adds complexity in build configuration, cross-ABI support, debugging, and maintenance across Android versions. Not all Android \glspl{api} are directly available through the \gls{ndk}, so bridging via \gls{jni} is often required for broad framework functionality \cite{android-ndk-concepts}. 

\subsection{\glsxtrlong{jni}}
The \gls{jni} (Java Native Interface) is a native programming interface that enables Java or Kotlin code running in a virtual machine to interoperate with libraries and applications written in C/C++ \cite{jni-spec-intro}. It allows managed code to call into native code, and for native code to call back into the \gls{vm}, manipulate Java objects, throw exceptions, and more. The \gls{jni} is designed to impose no restrictions on the implementation of the \gls{vm}, thereby preserving binary compatibility across \gls{vm} vendors \cite{jni-spec-intro}.  

Listing~\ref{lst:javaNative} shows a Java class declaring a \texttt{native} method, while Listing~\ref{lst:JNI} gives the corresponding C implementation on the native side.

\begin{lstlisting}[language=Java+JNI, caption={Java class declaring a \texttt{native} method}, label={lst:javaNative}] 
public class foo {
    private native double bar(int i, String s);
    static {
        System.loadLibrary("native-lib");
    }
}
\end{lstlisting}

\begin{lstlisting}[language=C+JNI, caption={Native implementation of \texttt{bar}}, label={lst:JNI}]
jdouble Java_pkg_foo_bar(JNIEnv *env,          // ptr to JNI interface
                         jobject obj,          // "this" pointer
                         jint i, jstring s) {  // first and second parameter
    return 0.0; /* Method implementation */
}
\end{lstlisting}


\begin{comment}
    \subsection{Vulnerabilities} %  and Impact on the Android Sandbox
Bugs in native memory safety remain the main cause of serious compromise on Android. 
Although the platform’s sandbox assigns each app a distinct \gls{uid} and constrains it further with SELinux policies, a native component compromised inside that boundary still runs with the app’s privileges and can expose any secrets or capabilities already permitted (e.g., tokens, stored content, or keys) \cite{android-app-sandbox,android-selinux}. In practice, this turns local corruption into high-impact data access or control-flow hijacking even without crossing process boundaries.
Memory-safety defects in native libraries, such as buffer overflows, out-of-bounds reads/writes, use-after-free, and double free, belong to well-known categories captured by \gls{cwe}, and they frequently appear in \gls{cve} records \cite{cwe-mitre,cve-overview}. On Android, these errors may manifest as application crashes, or in more severe cases permit arbitrary code execution or data tampering, depending on mitigations and exploitability assumptions \cite{android-native-risk}. 


Attackers often amplify impact by chaining flaws across interfaces. Many system services are native and reachable over Binder; memory corruption in such a service can be triggered via \gls{ipc} by a malicious client to escape app-level limits \cite{mao-nass-usenix25}. 

In other scenarios, native code may corrupt memory pages shared with the managed runtime (e.g. altering \gls{jni} or class metadata) by transgressing memory protection via system calls (e.g. \texttt{mprotect}), thus undermining Java-level safety invariants and enabling code injection or VM subversion \cite{going-native-ndss17}. 
Another common vector is outdated third-party native libraries: empirical studies show that a significant fraction of popular apps ship unpatched vulnerable native libraries, and that developers take on average hundreds of days to apply upstream patches \cite{almanee-icse21}. This “patch latency” enables attackers to exploit known vulnerabilities even in apps that seem benign at the Java layer.  

Mitigation requires defense-in-depth: modern Android hardening (ASLR/DEP, control-flow integrity, memory tagging), combined with strict interface design and timely library updates, can substantially raise exploitation cost even when bugs persist \cite{android-ndk-mte}. 
\end{comment}

\subsection{Vulnerabilities and Impact on the Android Sandbox}
Native memory-safety bugs remain a dominant cause of serious compromise on Android. Although the platform’s sandbox assigns each app a distinct \gls{uid} and further constrains it with SELinux policies, a native component compromised inside that boundary still runs with the app’s privileges and can expose secrets or capabilities already permitted (e.g., tokens, stored content, keys) \cite{android-app-sandbox,android-selinux}. In practice, this turns local corruption into high-impact data access or control-flow hijacking even without crossing process boundaries.

Memory-safety defects in native libraries, such as buffer overflows, out-of-bounds reads/writes, use-after-free, and double free, belong to well-known \gls{cwe} families and frequently appear in \gls{cve} records. %\cite{cwe-mitre,cve-overview} 
On Android, these errors may cause crashes or, in more severe cases, permit code execution or data tampering depending on mitigations and exploitability assumptions \cite{android-native-risk}.

Attackers often amplify impact by chaining flaws across interfaces. Many system services are native and reachable over Binder; memory corruption in such a service can be triggered via \gls{ipc} by a malicious client to bypass app-level limits \cite{mao-nass-usenix25}. In other scenarios, native code may corrupt memory shared with the managed runtime (e.g., altering \gls{jni} or class metadata) by abusing memory-protection system calls, undermining Java-level safety invariants and enabling code injection or \gls{vm} subversion \cite{going-native-ndss17}. Another common vector is outdated third-party native libraries: empirical studies show that a significant fraction of popular apps ship unpatched vulnerable native libraries, and that developers take on average hundreds of days to apply upstream patches \cite{almanee-icse21}. This patch latency enables exploitation of known bugs even in apps that appear benign at the Java layer.

% Mitigation requires defense-in-depth: modern Android hardening (\gls{aslr}/\gls{dep}, control-flow integrity, memory tagging), combined with strict interface design and timely library updates, can significantly reduce the feasibility and reliability of exploitation even when bugs persist \cite{android-ndk-mte}.

\section{Fuzzing}
Fuzzing is an automated testing technique that repeatedly executes a target program with many inputs, either randomly generated or systematically derived, to expose defects such as crashes, assertion failures, or memory-safety violations. Modern fuzzers prioritise inputs that increase code coverage (e.g., edge or block coverage), and couple execution with hardening oracles (e.g., sanitizers) to turn latent memory errors into reliable, actionable signals \cite{sutton2007fuzzing,godefroid2008sage}.

\subsection{Types}
A fuzzer can be classified along three ways:
\begin{itemize}
  \item \textbf{Input production:} \emph{generation-based} where inputs are produced from a model or specification and \emph{mutation-based} where inputs are produced by mutating existing seeds. Coverage-guided mutation fuzzers (e.g., AFL++, libfuzzer) iteratively mutate seeds that increase coverage.
  \item \textbf{Input knowledge:} \emph{structured}, grammar- or model-based, aware of input format/protocol, or \emph{unstructured}, no knowledge of structure; “dumb” or purely random.
  \item \textbf{Program knowledge:} \emph{black-box}: no visibility into internals, \emph{grey-box}: lightweight instrumentation, e.g., edge coverage, and \emph{white-box}: constraint solving/symbolic execution to systematically steer execution, as in SAGE \cite{godefroid2008sage}.
\end{itemize}

\subsection{Uses}
Fuzzing is primarily employed to discover security-relevant defects in safety- or security-critical software. Its strength lies in \emph{demonstrating the presence} of bugs via concrete, reproducible inputs. Proving correctness for all inputs requires a formal specification and formal methods; fuzzing complements, rather than replaces, such approaches \cite{sutton2007fuzzing}. In practice, fuzzing integrates into secure development lifecycles and Continuous Integration pipelines to continuously test libraries, parsers, and interfaces that process untrusted data.

\subsection{Android context} %  (sanitizers as oracles).
On Android, fuzzing native components benefits from memory error detectors such as Hardware-assisted AddressSanitizer (HWASan) and, historically, AddressSanitizer (ASan). These sanitizers instrument code to detect out-of-bounds accesses, use-after-free, and related violations during fuzzing, producing precise diagnostics that accelerate crash triage \cite{hwasan-ndk,asan-aosp,asan-clang}.

Two widely used coverage-guided engines are American Fuzzy Lop++ (AFL++) (a fork and extension of AFL with a rich ecosystem of mutators and instrumentation options) and LLVM In-Process Coverage-Guided Fuzzer (libFuzzer). Both have been successfully applied to native libraries, including on Android, to elicit high-quality crashes and to maximise coverage under realistic budgets \cite{aflpp-woot20,libfuzzer-llvm}.






\section{\glsxtrlong{llm}}
\glspl{llm} are deep neural networks based on the Transformer architecture, which replaces recurrence/convolution with stacked self-attention and feed-forward layers to model long-range dependencies efficiently \cite{vaswani2017attention}. Today’s \glspl{llm} are pre-trained on large corpora via next-token prediction and then adapted to follow user prompts. 

\subsection{Limitations and Hallucinations}
Because \glspl{llm} predict tokens rather than verify facts, they can generate confident but incorrect content (``hallucinations''). Surveys and recent studies document multiple forms (e.g., intrinsic or confabulated outputs) and show that even state-of-the-art models may produce fluent fabrications \cite{ji2023hallucination,farquhar2024semanticentropy}. In security-oriented workflows such as vulnerability triage, this can manifest as invented \gls{cve} identifiers, non-existent \glspl{api} or packages, fabricated proof-of-concept details, or misattributed stack traces, errors that can mislead severity assessment or waste analyst time. Empirical work on code-generation further highlights ``package hallucinations'', where models recommend non-existent libraries, creating supply-chain risk if an attacker later publishes a malicious package with that name \cite{spracklen2025package}. 
%Consequently, any use of \glspl{llm} for triage should treat outputs as hypotheses to be checked against authoritative sources and artefacts (code, binaries, advisories), and prefer designs that promote verifiability and uncertainty signalling rather than unconditional trust.



\section{\glsxtrlong{mcp}}
\gls{mcp} is an open protocol, introduced by Anthropic (creator of Claude) in November 2024, that standardises how \gls{ai} applications obtain and manage external context via a client–server architecture.
An \emph{MCP host} (the \gls{ai} application) connects to one or more \emph{MCP servers} through dedicated \emph{MCP clients}, enabling the host to discover and use tools, read resources, and apply prompts exposed by servers. The protocol separates \emph{data layer} (primitives, lifecycle, notifications) from a \emph{transport layer} (e.g., stdio for local, streamable HTTP for remote), so the same message semantics work across local and remote deployments \cite{mcp-architecture,mcp-intro, mcp-transports}. In brief, servers contribute context and actions; clients manage capability negotiation and exchanges; the host orchestrates everything in the user-facing application \cite{mcp-architecture,mcp-server-concepts,mcp-client-concepts}. Figure~\ref{fig:mcp-simple-diagram} provides a high-level view of this host–client–server pattern and example integrations.

\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikzpicture/mcp-simple-diagram}}
    \caption[High-level MCP architecture.]%
      {High-level \gls{mcp} architecture. The \gls{mcp} host (e.g., chat interface or IDE) coordinates one or more \gls{mcp} clients, each connected to an \gls{mcp} server that exposes tools, resources, and prompts \cite{mcp-intro}.}
    \label{fig:mcp-simple-diagram}
\end{figure}

\subsection{MCP Host}
The \gls{mcp} \emph{host} is the application the user directly interacts with (e.g., a chat UI or an IDE extension). It manages the overall user experience, session lifecycle, permissions, and tool exposure, and it instantiates one or more \gls{mcp} clients to talk to specific servers. In practice, the host governs policy (e.g., which servers are allowed, rate limits) and mediates the user-facing rendering of server responses \cite{mcp-architecture}. 
Figure~\ref{fig:mcp-interaction} situates the host on the left, coordinating multiple client–server links while preserving a single conversational surface for the user.

\subsection{MCP Client}
An \gls{mcp} \emph{client} is a protocol-level component created by the host to communicate with exactly one \gls{mcp} \emph{server}. Each client maintains a transport (stdio or HTTP/WS), negotiates capabilities, and exposes the server’s tools/resources/prompts to the host. This indirection lets the host manage several servers in parallel without coupling UI logic to any server implementation details \cite{mcp-client-concepts}. 
In Figure~\ref{fig:mcp-interaction}, clients appear as the ''middle`` connectors: they translate host intents (e.g., ''run tool T``) into \gls{api} call and relay the server’s results back to the host.

\subsection{MCP Server}
An \gls{mcp} \emph{server} wraps external systems (e.g. files, databases, reverse-engineering tools) and presents them as protocol objects: tools: invokable functions with JSON Schemas, resources: readable artefacts, and prompts: reusable task templates. Servers publish a capability manifest so that clients can discover what is available and how to access it. The \gls{mcp} \emph{server} provides tools that enable \glspl{llm} to perform actions, carry out deterministic computations and interact with external services. 
This design decouples model/UX from system integrations and enables reuse across different hosts and models \cite{mcp-tools}. 
In Figure~\ref{fig:mcp-interaction}, servers sit on the right, each encapsulating one integration boundary (e.g., Jadx, Ghidra, a code search index).

\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikzpicture/mcp-interaction}}
    \caption[MCP interaction]{MCP interaction: capability discovery, tool selection, invocation, and reply.}
    \label{fig:mcp-interaction}
\end{figure}

\subsection{Interaction}
Figure~\ref{fig:mcp-interaction} illustrates a typical flow. 
\begin{enumerate}
  \item The host initialises and lists available servers (or lets the user attach new ones). % cf. MCP architecture
  \item For each server, the host spawns a client that performs capability discovery (tools/resources/prompts and their schemas). % discovery
  \item When the user or an agentic workflow triggers an action, the host selects an appropriate tool and routes a request through the corresponding client to the target server. % routing
  \item The server executes the tool (e.g., decompile a class with Jadx, disassemble a function with Ghidra) and returns structured results to the client. % tool exec
  \item The client relays the structured results to the host; the host provides this context to the \gls{llm}, and may chain further tool calls. % host mediation + elicitation
  \item The \gls{llm} synthesises a user-facing response using the returned context; the host renders this reply in the UI (and records any artefacts/evidence links). % <-- added item
  \item The host may persist state and expose follow-up actions (e.g., re-run with new arguments, open related resources), maintaining a single conversational surface. % follow-ups
\end{enumerate}


\section{Vulnerability Scoring Systems}
Modern vulnerability workflows rely on interoperable standards that identify issues, classify their root causes, and communicate technical severity. 

\subsection{\glsxtrlong{cwe}}
The \gls{cwe} is a community-curated taxonomy of common software and hardware weakness types (e.g., buffer overflow, use-after-free). It provides standardised identifiers and structured descriptions to support detection, prevention, and education across the secure development lifecycle \cite{cwe-about}. Unlike CVE (which tracks specific \emph{instances}), \gls{cwe} captures \emph{classes} of underlying faults, enabling aggregation and trend analysis at the root-cause level \cite{cwe-list}.

\subsection{\glsxtrlong{cve}}
The \gls{cve} Programme assigns unique identifiers to publicly disclosed vulnerabilities, providing a single canonical reference for coordination across vendors, researchers, and users. A \gls{cve} entry names the specific issue (product, version, and vulnerability description) and links to public references; other databases may enrich it with severity and technical details \cite{cve-overview}. In practice, national or vendor repositories (e.g., \gls{nvd}) attach \gls{cvss} scores and map each \gls{cve} to one or more \gls{cwe} categories for analytics and prioritisation \cite{nvd-cve-process,cvss40-nvd-support}.

\subsection{\glsxtrlong{cvss}}
The \gls{cvss} is an open, vendor-neutral framework for describing the intrinsic characteristics and severity of a vulnerability through a set of metrics that yield a numerical score and qualitative severity band. \gls{cvss} communicates \emph{severity}, not overall \emph{risk}; operational risk assessment should incorporate asset context, threat activity, and environmental factors beyond the Base score \cite{cvss31-user-guide}.

\paragraph{Relation}
In triage and remediation workflows, \gls{cve} entries identify concrete vulnerabilities; each entry can be mapped to \gls{cwe} identifiers that explain the underlying weakness type; \gls{cvss} scores (often provided by downstream databases) express the vulnerability’s technical severity. Together, \gls{cwe}$\rightarrow$\gls{cve}$\rightarrow$\gls{cvss} forms a pipeline from root-cause taxonomy to instance tracking and severity quantification \cite{nvd-cve-process}.

\section{Reverse engineering}
Reverse engineering in software is the analysis of binaries or bytecode to recover design and implementation information-disassembly, control/data flows, and higher-level structure, when source or specifications are incomplete or unavailable \cite{springer-sre-overview,samuelson1990re}. In practice, reverse engineering workflows combine a disassembler/decompiler with cross-reference search, symbol inspection, and targeted decompilation to produce evidence suitable for auditing and triage.

\subsection{Ghidra}
Ghidra is an open-source software reverse-engineering framework developed by the National Security Agency (NSA. It provides disassembly, decompilation, graphing, and scripting across multiple architectures, and is widely used in vulnerability research and malware analysis \cite{ghidra-github}. 

\subsection{Jadx}

Jadx is a decompiler providing Java source code from Android Dex and Apk files, with \gls{cli} and \gls{gui} front-ends; it is commonly used to inspect Android manifests, classes, and resources. In the pipeline, Jadx supplies managed-side context (e.g., App manifest, class/method signatures, entry points).

