\chapter{Future Work}
\label{chp:futureWork}

This thesis has shown that an \gls{llm} equipped with \gls{mcp}-based access to Jadx and Ghidra can assist in the triage of crashes originating from native libraries in Android applications.  
Several implementations could be developed in the future, particularly to further improve the quality of the triage.


\section{Use of Specialised Models for Triage}

The current approach relies on general-purpose \glspl{llm}, guided through meta-prompts and tool use.  
Using models specifically adapted or trained for vulnerability analysis could improve stability, enhance recognition of recurring vulnerability patterns, and provide more consistent assessments across similar crashes.

%\textcolor{red}{find some example (pentestGPT ?)}

\section{Persistent Agents}

In the current implementation, each crash is analysed in isolation: the agent processes the crashes associated with a method, interacts with the tools, produces a report, and then its context is reset.  
A possible extension is to maintain a \emph{persistent} triage agent over time. That could be preceded by a lightweight training or calibration phase using an available ground-truth labeled   dataset.  
Such an approach would allow the agent to internalise verified classifications and use them as stable reference points in subsequent analyses.

A persistent agent could progressively accumulate knowledge about specific libraries, recurring code idioms, and previously classified vulnerabilities.  
For example, it could remember that a particular JNI library has already been associated with a confirmed buffer overflow and reuse this information when triaging future crashes involving the same code.  
It could also enforce dataset-wide consistency, ensuring that similar crash patterns across different APKs or execution traces receive comparable classifications and severity assessments.

\section{Use of \glsxtrlong{rag}}

\gls{rag} supplements an \gls{llm} with an external knowledge base that can be queried at inference time. 

Recent work shows that RAG can strengthen factual grounding in vulnerability analysis.  
LProtector\cite{sheng2024lprotectorllmdrivenvulnerabilitydetection} improves detection accuracy and explainability by retrieving security-relevant context, while VulRAG\cite{du2025vulragenhancingllmbasedvulnerability} demonstrates that retrieving similar vulnerabilities or code fragments leads to more reliable classification.

So, a possible extension would be to build a repository of pre-analysed APKs, crashes, and ground-truth labels, allowing the agent to retrieve historical cases similar to the current one.  
Using these annotated crashes as an external reference, as ground truth and as concrete comparison, could help the agent anchor its reasoning, reduce ambiguity, and improve the quality and consistency of the classification.


\section{\gls{llm}-Based Exploit Generation and Validation}

At the current stage, the agent is limited to analysing crashes and explaining possible root causes; it does not attempt to construct or validate concrete exploits.  
A natural extension would be to introduce a post-triage phase in which the \gls{llm} engages in an iterative reasoning-and-action cycle, similar to ReAct-style prompting.  
Given a crash, the agent would generate a candidate exploit input or harness modification, execute it in a controlled environment, observe the resulting behaviour and logs, and, if necessary, query additional code context via \gls{mcp}.  
Based on this feedback loop, the agent could refine or redesign the exploit attempt, repeating the process until the vulnerability is confirmed as either exploitable or not.

\section{GAN-like Multi-Agent Structure}

Another possible extension is to explore a GAN-like architecture composed of multiple \gls{llm} agents with opposing objectives.  
One agent would attempt to demonstrate that a crash is exploitable, while a second agent would argue the opposite by seeking alternative explanations or benign root causes.  
A third, neutral agent would then act as an adjudicator, evaluating the evidence produced by both sides and issuing the final classification.  
%Such an adversarial setup could expose weak or ambiguous reasoning, reduce overconfidence, and lead to more robust and better-grounded triage decisions.
