\chapter{Design}
\label{chp:design}

This chapter presents the conceptual design of the automated crash triage system.  
The goal is to define the overall workflow, the interaction model between the \gls{llm} and external tools, and the prompting strategy that enables reliable, explainable vulnerability assessments.

The design focuses on three complementary aspects:
\begin{enumerate}
    \item the architecture of the triage pipeline and its information flow;
    \item the prompting framework used to guide the \gls{llm};
    \item the tool-orchestration layer (shimming) that enables controlled access to \gls{mcp}-exposed capabilities.
\end{enumerate}

\section{Pipeline and Workflow Design}

The triage process is structured as a multi-stage pipeline in which the \gls{llm} acts as a reasoning engine, while static-analysis tools (Ghidra, Jadx) act as retrieval and inspection backends.

Figure~\ref{fig:pipeline_design} illustrates the workflow:

\begin{enumerate}
    \item The crash reports produced by POIROT are parsed into structured \texttt{CrashSummary} objects.
    \item Relevant native libraries are identified and loaded into Ghidra; the APK is opened in Jadx.
    \item The \gls{llm} receives a system-level meta-prompt defining its role, objectives, rules, and output schema.
    \item For each crash, a user prompt provides the runtime context (stack, termination reason, JNI bridge method, Java call graph).
    \item The model decides which tool calls to execute through the \gls{mcp}, such as:
    \begin{itemize}
        \item locating functions (\texttt{search\_functions\_by\_name});
        \item retrieving decompiled native code (\texttt{decompile\_function}, \texttt{disassemble\_function});
        \item exploring Java-side call sites (\texttt{get\_android\_manifest}, \texttt{get\_class\_sources}).
    \end{itemize}
    \item The \gls{llm} integrates retrieved evidence and produces a final JSON vulnerability report.
\end{enumerate}

The pipeline therefore embodies an *analysis loop*: crash context → retrieval via tools → reasoning → structured verdict.

\section{Prompting Strategy}

The prompting strategy plays a pivotal role in ensuring the consistency, validity, and safety of the generated analyses.  
Multiple established prompting techniques are employed, as categorised by the Prompt Engineering Guide\footnote{\url{https://www.promptingguide.ai/techniques}}.

\subsection{Meta Prompting (Primary Technique)}

The central system prompt (\texttt{DETECTION\_SYSTEM\_PROMPT}) acts as a \emph{meta-prompt}, as defined in the Prompt Engineering Guide.  
It prescribes:
\begin{itemize}
    \item the task definition (crash triage and vulnerability assessment);
    \item constraints on the reasoning process (data-flow tracing, validation steps, reachability analysis);
    \item which external tools may be used (MCP Jadx, MCP Ghidra);
    \item how intermediate evidence must be interpreted;
    \item strict output constraints (Pydantic-compliant JSON);
    \item behaviour when information is missing (no hallucinations; explicit limitations).
\end{itemize}

This technique defines the “cognitive profile” of the model and ensures uniformity across assessments.

\subsection{Tool-Augmented Reasoning (PAL / Automatic Tool Use)}

The system relies on *Program-Aided Language Models (PAL)* and *Automatic Reasoning and Tool-Use*, as defined in the Prompting Guide.  
The model:
\begin{itemize}
    \item determines autonomously which tool calls to issue;
    \item retrieves code, symbols, and metadata via MCP backends;
    \item integrates results before proceeding with reasoning.
\end{itemize}

This transforms the \gls{llm} from a text generator into an orchestrator of static-analysis queries.

\subsection{ReAct: Reason + Act Loops}

The design follows the ReAct paradigm:
\begin{itemize}
    \item \emph{Reason}: interpret stack traces, map frames to functions, identify suspicious patterns;
    \item \emph{Act}: invoke Ghidra or Jadx tools to confirm hypotheses;
    \item \emph{Reason}: integrate the new evidence and refine the assessment.
\end{itemize}

This is especially effective for triage, where hypotheses must be validated through code inspection.

\subsection{Implicit Chain-of-Thought}

While explicit chain-of-thought is not revealed in the output, the system prompt enforces a multi-step reasoning checklist:
\begin{enumerate}
    \item correlate runtime failure with native call site;
    \item trace data backward through native and Java call chains;
    \item determine whether inputs are attacker-controlled;
    \item evaluate reachability under realistic conditions;
    \item classify the vulnerability and assign a severity score.
\end{enumerate}

The model implicitly follows this pipeline to ensure reliable judgments.

\subsection{Prompt Chaining}

Each crash triggers:
\begin{itemize}
    \item an initial query,
    \item one or more MCP tool calls,
    \item a final structured verdict.
\end{itemize}

This sequential exchange mirrors the Prompt Chaining technique from the guide.

\subsection{Self-Consistency (Retry-Based)}

The system incorporates retry loops in the shimming layer:
\begin{itemize}
    \item malformed JSON → regenerate;
    \item insufficient evidence → request additional tool calls.
\end{itemize}

This reproduces the Self-Consistency technique, increasing robustness across models.

\subsection{Structured Output Constraints}

The output is strictly constrained by Pydantic schemas, ensuring machine-readability and preventing hallucinated fields.

\subsection{Techniques Not Used}

According to the Prompting Guide:
\begin{itemize}
    \item \textbf{Zero-shot} and \textbf{few-shot prompting}: not used.
    \item \textbf{Tree-of-Thought}: not used.
    \item \textbf{Retrieval-Augmented Generation (RAG)}:  
    \textcolor{red}{Possibile dubbio: l’uso degli MCP costituisce RAG?}  
    Tecnicamente, RAG implica una conoscenza esterna indicizzata (KB o corpus).  
    Qui l’LLM interroga strumenti di analisi statica, non un archivio testuale.  
    Pertanto non è RAG nei termini classici.
    \item \textbf{Automatic Prompt Engineering}: not used.
    \item \textbf{Graph Prompting}, \textbf{Multimodal CoT}: not used.
\end{itemize}

\section{Shimming Layer and MCP Integration}

\subsection{Motivation}

Native LLMs (GPT, Gemini API) can directly interact with MCP servers.  
Open-source models (e.g.\ Llama-based models via Ollama) do not natively support the MCP protocol nor the required turn-based tool-call constraints.

Additionally, the triage task requires contextual information that is:
\begin{itemize}
    \item not contained in the crash report,
    \item not embedded in the model’s parameters,
    \item dynamically retrievable only through static-analysis tools.
\end{itemize}

Examples include:
\begin{itemize}
    \item the decompiled body of the crashing function,
    \item cross-references to memory operations,
    \item resource lookups from the APK,
    \item Java call graph reconstruction.
\end{itemize}

Without this evidence, the model cannot reliably classify vulnerabilities.

\subsection{Design of the Shimming Layer}

The shimming layer acts as a mediator between the \gls{llm} and the MCP tool ecosystem by enforcing:
\begin{itemize}
    \item strict JSON-only communication;
    \item one tool call per turn;
    \item mandatory tool-use before outputting a final verdict;
    \item correct routing to Jadx-MCP or Ghidra-MCP servers;
    \item automatic correction of malformed model outputs;
    \item retries and error handling.
\end{itemize}

The LLM therefore remains “free” to choose \emph{which} information to retrieve, but is forced to do so within a safe, deterministic protocol.

\subsection{Why MCP Tools Are Needed}

The MCP integration enables:
\begin{itemize}
    \item \textbf{expanded context}: access to code, manifest, Java classes, native functions;
    \item \textbf{dynamic retrieval}: adaptively query deeper evidence when ambiguous crashes occur;
    \item \textbf{precision}: avoid hallucinated code by grounding analysis in real decompiled output;
    \item \textbf{transparency}: evidence is explicitly returned in the JSON result (file, function, snippet).
\end{itemize}

In essence, the MCP tools provide the LLM with “eyes” into the application’s codebase, transforming the model into a hybrid static-analysis reasoning agent.

\section{Summary}

The system design combines:
\begin{itemize}
    \item a multi-stage evidence-driven analysis pipeline,
    \item a rich meta-prompt defining the LLM’s reasoning behaviour,
    \item modern prompting techniques (Meta Prompting, PAL, ReAct, Chain-of-Thought),
    \item a robust shimming layer,
    \item and MCP-based integration with static-analysis tools.
\end{itemize}

This architecture enables reproducible, explainable, and tool-assisted vulnerability triage for JNI-based Android applications.

