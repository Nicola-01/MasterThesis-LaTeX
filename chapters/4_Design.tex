\chapter{Design}
\label{chp:design}

%design si riferisce alla fase di modellazione. Nel tuo caso, può essere la pipeline/il workflow che andrai a definire per interrogare gli LLM. Non so se i prompt vadano in design o implementation, poi vedremo...forse, implementation la toglieremo del tutto

This chapter presents the conceptual design of the automated crash–triage system.  The goal is to formalise the architecture, information flow, and reasoning model that underpin the use of \glspl{llm} for vulnerability triage of crashes  in Android native libraries.  


\section{Data Models}

A central element in the design of the crash–triage system is the definition of a set of structured data models that organise all information exchanged between components. 
Since the \gls{llm}-based analysis relies on precise, machine-readable context, every stage of the workflow—from parsing POIROT outputs, to extracting application metadata, to producing the final vulnerability assessment—depends on well-defined representations.
These models constrain how information is encoded, ensure consistency across analyses, and guide the \gls{llm} by enforcing a predictable input and output format.

In this project, all relevant information is captured through strongly typed objects such as \texttt{CrashSummary}, \texttt{AppMetadata}, and \texttt{VulnResult}. Their standardised structure guarantees that the \texttt{CrashSummary} provided to the \gls{llm} have always a consistent structure, divided into clearly defined fields that are explicitly explained in the system prompt and easily interpretable by the model. Likewise, the \texttt{AppMetadata} and \texttt{VulnResult} models allow the system to request a precise and schema-constrained output from the \gls{llm}, which must adhere to the predefined structure.

Instead of asking the model directly whether the app is vulnerable and why, the system instructs the \gls{llm} to populate a fixed JSON template containing all relevant fields, with strict type and content definitions, ensuring that output is both machine- and human-readable. This approach may improve \gls{llm} robustness and reduce variability in classification tasks, because schema-based prompting helps the model focus on the attributes relevant for the decision while avoiding drifting into irrelevant details.


Moreover, enforcing a fixed structure simplifies downstream processing: outputs can be exported as well-formed \texttt{JSON} files and automatically queried or aggregated across multiple applications. For example, after a full triage run, external utilities can group results by vulnerability verdict, severity level, or associated \gls{cwe} identifiers, inspect all low-confidence cases, or generate visual summaries such as the ratio of vulnerable versus benign crashes across Android versions. 

The crash report may also include a possible \gls{poc}, meaning that structured outputs can additionally support automated testing: external tools can more easily extract the commands suggested by the \gls{llm} and attempt to execute them for exploit verification. This capability is not guaranteed to work reliably in all cases, but a standardised output format makes such integration technically feasible and simplifies the development of external validation utilities.


The structured design therefore relies on a set of core data models, described below.


\begin{itemize}
    \item \textbf{CrashSummary} Represents a single crash extracted from the analysis report.\\  
    It encapsulates key fields such as the native stack frames, JNI bridge method, a reconstructed Java call graph, the set of native libraries involved in the stack trace, among other fields..  
    %This model provides to the agent all the information needed for classification.

    \item \textbf{AppMetadata}  
    Aggregates APK-level information extracted from Jadx, including:\\
    application name, package name, version code and version name, and minimum/target SDK levels.
    %This object contextualises the crash within the application environment.

    \item \textbf{VulnResult}  
    Represents the structured output of the \gls{llm} for a single crash.\\
    It exposes information such as the chain of thought, vulnerability verdict,  CWE identifiers, severity level and an optional exploitability assessment via the \texttt{Exploit} object, as well as other contextual information.
    %Strict field definitions ensure stable parsing of \gls{llm} output.

    \item \textbf{Exploit}
    Describes the exploitability of a suspected vulnerability.\\
    It contains key fields such as the exploitability rating (unknown / theoretical / practical), the required environmental prerequisites, and Proof of Concept commands, alongside additional optional elements.
    %This model enables the \gls{llm} to assess not only the presence of a vulnerability but also its operational impact.
\end{itemize}

\subsubsection{Additional Structures}

\textbf{EvidenceItem} stores an piece of evidence used by the \gls{llm} to justify its reasoning, such as a function name, memory address, short decompiled snippet, and an associated explanatory note.  

\noindent\textbf{Statistics} collects metrics on model usage (tokens, requests, wall-clock time), enabling performance profiling and cost monitoring during large-scale triage.

\medskip

Overall, this strict modelling architecture ensures resilience against malformed or incomplete \gls{llm} outputs and provides a deterministic structure for downstream processing, evaluation, and reproducibility.

\section{Prompt Design}\label{chp:prompt}

A central component of the system design is the structure of the prompts used to guide the \gls{llm}.  
Because the triage procedure requires multi-step reasoning, explicit interaction with \gls{mcp} tools, and the generation of JSON outputs. The quality and organisation of the prompts directly determine the reliability of the analysis.  
Well-designed prompts reduce ambiguity and also provide a stable decision-making model, ensuring consistent behaviour across different applications and crashes.

%The prompts adopted in this work follow a hybrid structure:  a \textit{system-level meta-prompt} that defines the global reasoning procedure.

\subsection{Vulnerability Triage Prompt}

The core of the system is the vulnerability triage prompt, which governs how the \gls{llm} analyses each crash and produces its final assessment.  
The prompt employs \emph{meta prompting}\cite{zhang2025metapromptingaisystems}: the system prompt defines the agent’s role, the overall reasoning procedure, the rules for interacting with \gls{mcp} tools, and the exact JSON structure that the model must produce.  
This provides the model with a stable cognitive frame and constrains its behaviour.

In addition, the prompt enforces an implicit form of \emph{Chain-of-Thought} reasoning\cite{wei2023chainofthoughtpromptingelicitsreasoning}.  
Although the internal chain of thought is not exposed in the output, the model is instructed to follow a multi-step analytical path—starting from the crashing frame, performing backward reasoning, checking reachability, and validating assumptions—before emitting the final classification.

\subsection{Structure of the Prompt}

The prompt used for vulnerability triage is organised into a set of structured components that collectively define the agent's behaviour, analysis procedure, and output constraints.  
Rather than providing ad-hoc instructions, the prompt specifies a complete operational framework that the \gls{llm} must follow when examining each crash.  
Its structure can be understood through four conceptual layers.

\paragraph{1. Role and behavioural specification.}
The prompt begins by defining the role of the agent, its objectives, and the scope of the analysis.  
It instructs the model to behave as a vulnerability analyst with access to static-analysis tools, explicitly prohibiting unsupported assumptions, unverifiable statements, and speculative reasoning.  
Clear behavioural rules constrain how the agent must reason about the crash, how it should handle missing information, and how it should justify its conclusions.

\paragraph{2. Interpretation of inputs.}
The prompt describes in detail the meaning and expected use of the inputs provided for each crash: the native stack trace, the JNI bridge method, the Java call graph, and the list of relevant libraries.  
The model is instructed to integrate these artefacts into a coherent execution path.  
In particular, it must reconstruct the control flow starting from the point of failure and reason backwards to identify the root cause, assessing whether the crash is plausibly reachable and whether user-controlled data may influence the faulting operation.

\paragraph{3. Tool-use protocol.}
A dedicated section of the prompt defines how the agent must interact with external tools exposed through the \gls{mcp}.  
The model is told when tool calls are appropriate, which information each tool can provide, and how retrieved evidence should influence the ongoing analysis.  
This ensures that tool invocations are purposeful and integrated into the reasoning loop.

\paragraph{4. Structured output requirements.}
The final part of the prompt imposes strict output constraints.  
The model must produce a JSON object consistent with a predefined schema, filling fields such as the vulnerability verdict, confidence score, severity, CWE identifiers, and other.
Each field is accompanied by explicit instructions describing what constitutes a valid value and how the agent should justify its decisions.

Overall, this structured prompt acts as a complete analytical workflow: it defines how the \gls{llm} interprets inputs, how it retrieves additional evidence, how it reasons about the execution path, and how it produces a verifiable and reproducible vulnerability assessment.



\begin{comment}
    The present chapter focuses on the \textcolor{red}{modelling choices ???}, the high-level workflow, the prompting principles, and the integration logic required to expose reverse-engineering evidence to the \gls{llm} via the \gls{mcp}.

Following best practices in system design, the design is organised around three pillars:
\begin{enumerate}
    \item a multi-stage analysis pipeline that governs the end-to-end data flow;
    \item a prompting and agent \textcolor{red}{framework} that constrains and guides the \gls{llm}'s behaviour;
    \item a shimming layer that guarantees correct, deterministic, and protocol-compliant interaction between the \gls{llm} and external tools. \textcolor{red}{mmhh}
\end{enumerate}

The remainder of this chapter expands each of these components in detail.
\end{comment}

\section{Pipeline Architecture} %  [Pipeline and Workflow Design]
\label{sec:pipeline_design}

The triage pipeline is designed as a structured, evidence-driven reasoning process. Its objective is to enrich the raw crash artefacts produced by POIROT with code-level context, enabling the \gls{llm} to formulate grounded judgements.

Figure~\ref{fig:pipeline_overview} provides an overview of the full workflow, which integrates: (i) POIROT’s fuzzing output, (ii) static-analysis backends exposed via \glspl{mcp}, and (iii) the \gls{llm} configured with a strict meta-prompt and output schema.

\begin{figure}[!ht]
    \centering
    \scalebox{0.8}{\input{tikzpicture/pipeline_design}}
    \caption{Overview of the triage pipeline combining POIROT fuzzing, crash analysis, and \gls{mcp}-based inspections.}
    \label{fig:pipeline_overview}
\end{figure}

The pipeline consists of the following stages.

\subsection{Crash Report Parsing}% (\texttt{CrashSummary})}

At the start of the pipeline, the tool retrieves the \texttt{folder2backtraces.txt} files (Listing~\ref{lst:POIROT-output}) generated by POIROT.  
These raw crash reports contain the native stack traces, from which the process termination cause and the JNI entry point can be extracted.

For each crash, the system constructs a corresponding \texttt{CrashSummary} object, which combines the information extracted from the crash report with additional data required for the triage.

\begin{itemize}
    \item \textbf{Native Stack Trace}: the raw output produced by POIROT, consisting of the sequence of native frames leading to the crash.
    \item \textbf{JNI Bridge Method}: identified by decoding the \gls{jni} signature extracted from the crash, allowing the system to locate the corresponding Java declaration within the \gls{apk} (Listing~\ref{lst:JNI}).
    \item \textbf{Java call graph}: obtained by filtering the FlowDroid-generated call graph\footnote{\url{https://github.com/secure-software-engineering/FlowDroid}} to retain only the paths relevant to the crash.  
    This helps the \gls{llm} analyse the Java-side control flow more easily and increases the coverage of the application during triage.
    \item \textbf{Libraries and methods map}: using the stack-trace information, the tool identifies which native library contains each frame involved in the crash (including the JNI bridge). This provides the \gls{llm} with a compact map of all methods in the stack trace and the \texttt{.so} file in which each one resides.
\end{itemize}


\subsection{Initialisation and Context Loading}

Once the crashes have been normalised, the system prepares the analysis environment by loading the necessary application artefacts into the static-analysis tools.  
The target APK is opened in Jadx to expose its manifest and Java classes, while the relevant native libraries are imported into Ghidra for disassembly and decompilation.

\textbf{Note.}  
Although Ghidra supports loading multiple binaries within the same project, doing so significantly increases start-up time and expands the set of libraries that the model may query, often without yielding additional useful information.  
For this reason, only a filtered subset of libraries is loaded, as described in Section~\ref{chp:LibFiltering}.

At this point no \gls{llm} reasoning has been performed yet.  
This stage is purely preparatory: it ensures that the \glspl{mcp} can access all artefacts the model may request during the triage process.


\subsection{Agent Setup}

Before any crash is analysed, the \gls{llm} agent receives a \emph{system prompt} that defines its role as a vulnerability triage agent and constrains its reasoning process.  
This prompt outlines the analysis pipeline the model must follow (see Section~\ref{chp:prompt}), explains how to interpret the inputs provided in the user prompt, and specifies the structure and purpose of the JSON output.  
It also informs the agent of the available \glspl{mcp} and clarifies when tool calls should be used.  


\subsection{Crash Prompting}

For each crash, a dedicated \emph{user prompt} provides the corresponding \texttt{CrashSummary}, which contains all the information required by the \gls{llm} to perform the analysis.  
In addition to the native stack trace, the \texttt{CrashSummary} includes the filtered Java call graph leading to the JNI entry point, as well as the mapping of libraries and methods involved in the fault.  
This ensures that the model receives a concise yet complete representation of the execution path, covering both the Java and native layers relevant to the crash.

In case of multiple crash of the same method, the agent will remain the same, is only provide with the new crash to classified as a user prompt, but the agent it's not reseted, so it already known some apk/librari stracture


\subsection{Tool-Mediated Reasoning}

During the analysis, the model is free to decide which tool to invoke and when to invoke it, with the objective of retrieving the evidence required for the classification.  
Although the system prompt provides a suggested pipeline for collecting information, this sequence is not enforced; instead, it serves as a guideline.  
The agent can adaptively select the most appropriate \gls{mcp} call based on the evidence needed to advance its reasoning, allowing the triage process to remain flexible while still grounded in verifiable tool-assisted retrieval.


\subsection{Report Generation} % [Evidence Integration and Final Report Generation]}

Once sufficient evidence has been gathered, the \gls{llm} synthesises a structured assessment, returned as a \texttt{VulnResult}. 
The output follows a constrained JSON schema:
\begin{itemize}
    \item The \textbf{vulnerability verdict} and associated \textbf{confidence score}, the confidence should reflect the degree to which the classification is considered accurate;
    \item A \textbf{classification reasons};
    \item \textbf{\gls{cwe} identifiers} and the \textbf{estimated severity};
    \item List of \textbf{implicated libraries} and \textbf{affected functions};
    \item The relevant execution paths \textbf{Java--to--native call};
    \item Set of supporting \textbf{``reasons''} grounding the decision;
    \item Structured \textbf{evidence items}, including code excerpts, function names, addresses, and explanatory notes;
    \item \textbf{Explicit} assumptions, \textbf{limitations}, and recommended \textbf{mitigation steps}.
\end{itemize}

If \texttt{is\_vulnerability} is \texttt{true}, the result also includes a \texttt{Exploit} object providing a detailed exploitability analysis:

\begin{itemize}
    \item Exploitability level (\textit{none}, \textit{theoretical}, or \textit{practical});
    \item Triggering method (mechanism required to activate the vulnerability);
    \item Environmental or permission \textbf{prerequisites};
    \item The ordered \textbf{exploitation pipeline} describing the full attack flow;
    \item Copy-and-paste-ready \textbf{PoC commands} (e.g.\ ADB or shell commands).
\end{itemize}

The final report is entirely machine-readable and encapsulates both the analytical process and the supporting evidence.  
This makes it suitable not only for human manual inspection, but also for automated downstream processing, such as filtering high-severity findings, or generating aggregated statistics across multiple applications.  



\subsection{Evidence Integration and Final Report Generation}

For each crash identified in an application, the system first constructs a \texttt{CrashSummary}, which captures the execution context and the native failure characteristics in a structured format. This object is passed to the \gls{llm}, together with the relevant \texttt{AppMetadata}, enabling the model to perform a contextualised classification without relying solely on free-form prompts.

The \gls{llm} processes this information and returns a structured \texttt{VulnResult}, which contains the vulnerability verdict, supporting evidence, confidence estimates, CWE identifiers, reconstructed execution paths, and optional exploitability information. The tool then stores this result together with the processed crash and usage statistics (e.g.\ token counts, request time) in an \texttt{AnalysisResults} object.

Finally, each analysis run is encapsulated in an \texttt{AnalysisBlock}, which bundles:
\begin{itemize}
    \item the full set of \texttt{AnalysisResults} for the application,
    \item the corresponding \texttt{AppMetadata},
    \item and the tool-level metadata, including the \gls{llm} model used and tool version.
\end{itemize}

The \texttt{AnalysisBlock} is serialised as a well-formed \texttt{JSON} file, allowing the entire pipeline---from crash extraction to final assessment---to be exported, archived, and automatically processed by external tools. This enables downstream tasks such as aggregating results across multiple applications, filtering by severity or CWE class, performing statistical analyses, or integrating the outputs into larger testing and validation workflows.

\begin{comment}

\section{Prompting Framework [Prompting Strategy]}
\label{sec:prompting_strategies}

The prompting logic combines several complementary techniques.  
The design aims to strike a balance between flexibility (letting the model autonomously explore
the codebase) and reliability (preventing hallucinations and invalid reasoning paths).

\subsection{Meta Prompting (Primary Technique) [Meta Prompting (Primary Technique)]}

Meta prompting remains the main mechanism: the \gls{llm} is anchored by a strong, global
instruction set that defines its analytical style, the triage rubric, and the reporting schema.

\subsection{Tool-Augmented Reasoning [Tool-Augmented Reasoning (PAL / Automatic Tool Use)]}

The system uses a PAL-like pattern, where the LLM:
\begin{enumerate}
    \item identifies missing information,
    \item issues a tool call via the \gls{mcp},
    \item incorporates the response into its internal chain of reasoning.
\end{enumerate}

\subsection{ReAct: Reason + Act Loops [ReAct: Reason + Act Loops]}

The design optionally leverages ReAct patterns:  
the model first \emph{thinks}, then \emph{acts}, then \emph{reasons again} based on retrieved evidence.

\subsection{Implicit Chain-of-Thought [Implicit Chain-of-Thought]}

For safety and reproducibility reasons, explicit Chain-of-Thought is not returned to the user.  
However, the prompting encourages implicit reasoning within the model, constrained by tool-based grounding.

\subsection{Prompt Chaining [Prompt Chaining]}

Complex analyses sometimes require multi-step prompting,
particularly when Java-side context must be chained with native information.

\subsection{Self-Consistency [Self-Consistency (Retry-Based)]}

The system enforces retry mechanisms for malformed JSON or inconsistent responses, improving robustness.

\subsection{Structured Output Constraints [Structured Output Constraints]}
All results must conform to the predefined Python/Pydantic models.  
This ensures referential transparency and prevents ambiguous free-text responses.

\subsection{Techniques Not Used [Techniques Not Used]}
\textcolor{red}{To be reviewed.}  
Some prompting strategies (e.g.\ temperature scaling, prompt ensembles) were intentionally excluded
to maintain determinism.

\end{comment}

\section{Output Structure}

The final stage of the triage pipeline produces a structured and self-contained JSON report.  
This report contains all the contextual information required to understand the environment in which the analysis was performed, the metadata of the analysed \gls{apk}, and the full set of vulnerability assessments produced for each crash detected in the native libraries.

Each report is written to: \texttt{<out-dir>/<pkg>/<JNImethod>/report.json}

Listing~\ref{lst:jsonOutput} shows an example of the final JSON output.  
%The structure is defined by the \texttt{AnalysisContainer}, \texttt{AnalysisBlock}, and \texttt{AnalysisResult}.

\paragraph{Structure overview.}
The top-level object contains a single field, \texttt{analysis}, wrapping all the relevant metadata and results:

\begin{itemize}
  \item \textbf{\texttt{analysis.tool}} (\texttt{ToolInfo})  
  Describes the environment and configuration used for the triage:
  \begin{itemize}
    \item \texttt{model\_name}: identifier of the \gls{llm} used (e.g.\ \texttt{"gemini-cli"}, \texttt{"gpt-oss:120b"}).
    \item \texttt{apk\_path}: path to the analysed APK (e.g.\ \texttt{"APKs/com.tplink.skylight/base.apk"}).
    \item \texttt{version}: internal version of the triage tool.
  \end{itemize}

  \item \textbf{\texttt{analysis.app}} (\texttt{AppMetadata})  
  Contains the application metadata extracted from Jadx:
  \begin{itemize}
    \item \texttt{app\_name}: human-readable application label.
    \item \texttt{package}: package name (application identifier).
    \item \texttt{min\_sdk}, \texttt{target\_sdk}: minimum and target Android SDK levels.
    \item \texttt{version\_name}, \texttt{version\_code}: versioning information of the analysed build.
  \end{itemize}

  \item \textbf{\texttt{analysis.analysisResults}} (\texttt{AnalysisResults})  
  A list of per-crash assessments. Each element is an \texttt{AnalysisResult} object bundling:
  \begin{itemize}
    \item \texttt{crash} (\texttt{CrashSummary}): a normalised description of the crash:
    \begin{itemize}
      \item \texttt{ProcessTermination}: crash cause as reported by the runtime..
      \item \texttt{StackTrace}: list of native frames involved in the crash.
      \item \texttt{JavaCallGraph}: Java $\rightarrow$ JNI call chain leading to the JNI bridge method.
      \item \texttt{JNIBridgeMethod}: JNI entry point associated with the crash.
      \item \texttt{JavaCallGraph}: Java call chain leading to the JNI method.
      \item \texttt{FuzzHarnessEntry}: fuzzer entry function used to drive inputs.
      \item \texttt{ProgramEntry}: process entry point.
      \item \texttt{LibMap}: native libraries involved in the crash.

    \end{itemize}

    \item \texttt{assessment} (\texttt{VulnResult}): the vulnerability triage produced by the \gls{llm}:
    \begin{itemize}
      \item \texttt{chain\_of\_thought}: a list of strings representing the step-by-step monologue that LLM thinks through before classifying.
      \item \texttt{is\_vulnerable}: boolean verdict indicating whether the crash is likely a real vulnerability.
      \item \texttt{confidence}: numerical confidence in $[0,1]$ associated with the verdict.
      \item \texttt{reasons}: short textual bullets explaining the decision (e.g. missing null-termination, out-of-bounds read).
      \item \texttt{cwe\_ids}: list of relevant CWE identifiers (e.g.\ \texttt{"CWE-125"} for out-of-bounds read).
      \item \texttt{severity}: estimated impact level (\texttt{"low"}, \texttt{"medium"}, \texttt{"high"}, \texttt{"critical"} or \texttt{null} if unknown).
      \item \texttt{affected\_libraries}: list of libraries implicated in the crash.
      \item \texttt{recommendations}: concrete mitigation or follow-up actions (e.g.\ enforcing null-termination, adding bounds checks).
      \item \texttt{assumptions}: explicit assumptions made by the model (e.g.\ nature of the input or control over certain parameters).
      \item \texttt{limitations}: known gaps in the analysis (e.g.\ partial decompilation, missing source, lack of full context).
      \item \texttt{evidence}: list of \texttt{EvidenceItem} objects, each optionally containing:
        \begin{itemize}
            \item \texttt{function}: function name relevant to the issue.
            \item \texttt{address}: code address within the library (when available).
            \item \texttt{file}: library or source file associated with the evidence.
            \item \texttt{snippet}: short decompiled excerpt or code fragment.
            \item \texttt{note}: explanation of why this snippet supports the classification
        \end{itemize}

       \item \texttt{Statistics}: basic metrics on the analysis.
        \begin{itemize}
            \item \texttt{time}: total analysis time.
            \item \texttt{llm\_requests}: number of LLM requests.
            \item \texttt{llm\_tool\_calls}: number of MCP tool calls.
            \item \texttt{input\_tokens}: tokens sent to the LLM.
            \item \texttt{output\_tokens}: tokens produced by the LLM.
        \end{itemize}
    \end{itemize}
  \end{itemize}
\end{itemize}

This schema makes the output both human-readable and machine-consumable. 